{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28275e90-dfb7-43b1-bc46-e6ba779104e6",
   "metadata": {},
   "source": [
    "# Module-Topic Title\n",
    "This notebook will walk through ...\n",
    "\n",
    "## Background/Conceptual Overview\n",
    "Add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5684d7-2d81-4b41-a973-1f21a6b7cd61",
   "metadata": {},
   "source": [
    "# Content Overview \n",
    "\n",
    "- [Prerequisites](#prerequisites)\n",
    "- Add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d01cc-753b-458e-baa4-98e846c92867",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "A NIM (NVIDIA Inference Microservice) is a cloud-hosted AI model service. It lets you access hundreds models like Llama, NeMo, and Mistral through a single API, with optimized performance and control for building real-time applications like agents or digital humans. \n",
    "\n",
    "Prior to getting started, you will need an API Key from the NVIDIA API Catalog to access the models used in this notebook.\n",
    "  1. Navigate to **[NVIDIA API Catalog](https://build.nvidia.com/explore/discover)**.\n",
    "  2. Select any model, such as `llama-3.3-70b-instruct`.\n",
    "  3. On the right panel above the sample code snippet, click on \"Get API Key\". This will prompt you to log in if you have not already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627bc4e5-bac9-48cf-8f83-b19e5cf04567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can uncomment below to bypass your API KEY.\n",
    "#NVIDIA_API_KEY=\"yourapikey\"\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
