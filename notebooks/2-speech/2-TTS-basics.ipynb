{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841b4dfd",
   "metadata": {},
   "source": [
    "# NVIDIA-Pipecat Text to Speech Basics\n",
    "\n",
    "The RivaTTSService class lets you use NVIDIA’s Riva Text-to-Speech (TTS) models, either on a local server or via NVIDIA’s cloud (NVCF). Below showcases a simple example using the NVCF endpoint to send text in, and audio out.\n",
    "\n",
    "## Setup and Prerequisites\n",
    "Before running this notebook, make sure you have:\n",
    "- An NVIDIA API key for accessing cloud-hosted models via NVCF: [build.nvidia.com](build.nvidia.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c3fa1-bbbb-4502-a113-6acd3554877e",
   "metadata": {},
   "source": [
    "## Setup Environment and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0823bb-ab98-4abf-9849-7779418111d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter Your NVIDIA API KEY\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faeacea7-96dd-40fb-97cd-1beda2c12b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pipecat.frames.frames import EndFrame, TTSSpeakFrame\n",
    "from pipecat.pipeline.pipeline import Pipeline\n",
    "from pipecat.pipeline.runner import PipelineRunner\n",
    "from pipecat.pipeline.task import PipelineTask\n",
    "from nvidia_pipecat.services.nvidia_llm import NvidiaLLMService\n",
    "from nvidia_pipecat.services.riva_speech import RivaASRService, RivaTTSService\n",
    "from pipecat.transports.local.audio import LocalAudioTransport, LocalAudioTransportParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa08fbe-a2cc-407b-93e2-551aadbb1318",
   "metadata": {},
   "source": [
    "# Define the TTS Service\n",
    "The RivaTTSService provides high-quality speech synthesis using NVIDIA’s Riva TTS models. It supports multiple voices, languages, and custom dictionaries for pronunciation. The RivaTTSService class specifically handles:  \n",
    "- Connection to a TTS Server (API key or local)\n",
    "- Voice selection\n",
    "- Language and sample rate\n",
    "- Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dd1f7d-b4c9-43f7-9675-1c9c59010ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our text to speech service\n",
    "tts = RivaTTSService(\n",
    "    api_key=os.getenv(\"NVIDIA_API_KEY\"), # set API Key\n",
    "    voice_id= \"English-US.Female-1\",  # define the voice\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc34d0c-2791-4cc8-b2e1-db75cbecf59e",
   "metadata": {},
   "source": [
    "Enter any text below to generate speech and hear the result. You can try different messages to test how the voice sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be304f3-1905-4c0e-b9bc-1d50af03c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the message to change the text to speech output, then run the next cell again\n",
    "message=\"Hello there, how is it going!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745d9d44-11e6-44b5-a525-cdd02a1fd62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 11:00:04.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m177\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#0 -> RivaTTSService#0\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:04.750\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m177\u001b[0m - \u001b[34m\u001b[1mLinking RivaTTSService#0 -> LocalAudioOutputTransport#0\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:04.750\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m177\u001b[0m - \u001b[34m\u001b[1mLinking LocalAudioOutputTransport#0 -> PipelineSink#0\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:04.751\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m177\u001b[0m - \u001b[34m\u001b[1mLinking PipelineTaskSource#0 -> Pipeline#0\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:04.751\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m177\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#0 -> PipelineTaskSink#0\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:04.751\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 started running PipelineTask#0\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:05.754\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnvidia_pipecat.services.riva_speech\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m172\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [Hello there, how is it going!]\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:06.002\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m224\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2025-05-01 11:00:08.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 finished running PipelineTask#0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    transport = LocalAudioTransport(LocalAudioTransportParams(audio_out_enabled=True))\n",
    "\n",
    "    pipeline = Pipeline([tts, transport.output()]) # We define our RivaTTS Service in the Pipeline\n",
    "\n",
    "    task = PipelineTask(pipeline)\n",
    "\n",
    "    async def say_something():\n",
    "        await asyncio.sleep(1)\n",
    "        await task.queue_frames([TTSSpeakFrame(message), EndFrame()])\n",
    "\n",
    "    runner = PipelineRunner(handle_sigint=False if sys.platform == \"win32\" else True)\n",
    "\n",
    "    await asyncio.gather(runner.run(task), say_something())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nv-pipecat-env",
   "language": "python",
   "name": "nv-pipecat-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
